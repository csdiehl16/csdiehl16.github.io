<!DOCTYPE html><html lang="en" class="antialiased break-words"> <head><!-- Google tag (gtag.js) --><script type="text/partytown" async src="https://www.googletagmanager.com/gtag/js?id=G-NMTRKRDQZV"></script><script type="text/partytown">
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-NMTRKRDQZV');
        </script><!-- High Priority Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Building an AI-powered data explorer | Caleb Diehl</title><meta name="generator" content="Astro v4.16.18"><!-- Fonts --><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400..700&display=swap" rel="stylesheet"><!-- Low Priority Global Metadata --><link rel="icon" type="image/svg+xml" href="/favicon.svg"><link rel="sitemap" href="/sitemap-index.xml"><link rel="alternate" type="application/rss+xml" href="/rss.xml" title="RSS"><!-- Page Metadata --><link rel="canonical" href="https://csdiehl16.github.io/blog/post-3/"><meta name="description" content=""><!-- Open Graph / Facebook --><meta property="og:type" content="article"><meta property="og:url" content="https://csdiehl16.github.io/blog/post-3/"><meta property="og:title" content="Building an AI-powered data explorer | Caleb Diehl"><meta property="og:description" content=""><meta property="og:image" content="https://csdiehl16.github.io/ai_images/ai_scatter_example.png"><meta property="og:image:alt" content="An interactive notebook for visualizing data using AI"><!-- X/Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://csdiehl16.github.io/blog/post-3/"><meta property="twitter:title" content="Building an AI-powered data explorer | Caleb Diehl"><meta property="twitter:description" content=""><meta property="twitter:image" content="https://csdiehl16.github.io/ai_images/ai_scatter_example.png"><meta name="twitter:image:alt" content="An interactive notebook for visualizing data using AI"><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><link rel="stylesheet" href="/astro/carbon-calculator.YDQvaYZj.css">
<style>h2{margin:2.5rem .5rem}p,li{margin:1.5rem .5rem;font-size:1rem;line-height:1.25rem}a{font-weight:700;--tw-text-opacity: 1;color:rgb(55 174 204 / var(--tw-text-opacity, 1))}code{font-family:Consolas,monospace;--tw-text-opacity: 1;color:rgb(156 163 175 / var(--tw-text-opacity, 1))}pre{margin-left:.5rem;margin-right:.5rem;border-radius:.5rem;padding:1rem}
</style><script type="module" src="/astro/hoisted.YW3grJYV.js"></script>
<script>!(function(w,p,f,c){if(!window.crossOriginIsolated && !navigator.serviceWorker) return;c=w[p]=Object.assign(w[p]||{},{"lib":"/~partytown/","debug":false});c[f]=(c[f]||[]).concat(["dataLayer.push"])})(window,'partytown','forward');/* Partytown 0.11.0 - MIT QwikDev */
const t={preserveBehavior:!1},e=e=>{if("string"==typeof e)return[e,t];const[n,r=t]=e;return[n,{...t,...r}]},n=Object.freeze((t=>{const e=new Set;let n=[];do{Object.getOwnPropertyNames(n).forEach((t=>{"function"==typeof n[t]&&e.add(t)}))}while((n=Object.getPrototypeOf(n))!==Object.prototype);return Array.from(e)})());!function(t,r,o,i,a,s,c,l,d,p,u=t,f){function h(){f||(f=1,"/"==(c=(s.lib||"/~partytown/")+(s.debug?"debug/":""))[0]&&(d=r.querySelectorAll('script[type="text/partytown"]'),i!=t?i.dispatchEvent(new CustomEvent("pt1",{detail:t})):(l=setTimeout(v,(null==s?void 0:s.fallbackTimeout)||1e4),r.addEventListener("pt0",w),a?y(1):o.serviceWorker?o.serviceWorker.register(c+(s.swPath||"partytown-sw.js"),{scope:c}).then((function(t){t.active?y():t.installing&&t.installing.addEventListener("statechange",(function(t){"activated"==t.target.state&&y()}))}),console.error):v())))}function y(e){p=r.createElement(e?"script":"iframe"),t._pttab=Date.now(),e||(p.style.display="block",p.style.width="0",p.style.height="0",p.style.border="0",p.style.visibility="hidden",p.setAttribute("aria-hidden",!0)),p.src=c+"partytown-"+(e?"atomics.js?v=0.11.0":"sandbox-sw.html?"+t._pttab),r.querySelector(s.sandboxParent||"body").appendChild(p)}function v(n,o){for(w(),i==t&&(s.forward||[]).map((function(n){const[r]=e(n);delete t[r.split(".")[0]]})),n=0;n<d.length;n++)(o=r.createElement("script")).innerHTML=d[n].innerHTML,o.nonce=s.nonce,r.head.appendChild(o);p&&p.parentNode.removeChild(p)}function w(){clearTimeout(l)}s=t.partytown||{},i==t&&(s.forward||[]).map((function(r){const[o,{preserveBehavior:i}]=e(r);u=t,o.split(".").map((function(e,r,o){var a;u=u[o[r]]=r+1<o.length?u[o[r]]||(a=o[r+1],n.includes(a)?[]:{}):(()=>{let e=null;if(i){const{methodOrProperty:n,thisObject:r}=((t,e)=>{let n=t;for(let t=0;t<e.length-1;t+=1)n=n[e[t]];return{thisObject:n,methodOrProperty:e.length>0?n[e[e.length-1]]:void 0}})(t,o);"function"==typeof n&&(e=(...t)=>n.apply(r,...t))}return function(){let n;return e&&(n=e(arguments)),(t._ptf=t._ptf||[]).push(o,arguments),n}})()}))})),"complete"==r.readyState?h():(t.addEventListener("DOMContentLoaded",h),t.addEventListener("load",h))}(window,document,navigator,top,window.crossOriginIsolated);;(e=>{e.addEventListener("astro:before-swap",e=>{let r=document.body.querySelector("iframe[src*='/~partytown/']");if(r)e.newDocument.body.append(r)})})(document);</script></head> <body class="bg-main text-main"> <div class="flex flex-col min-h-screen"> <nav class="box-border m-2 sticky top-2 flex items-start z-20" data-astro-cid-dmqpwcec> <div class="w-full flex items-center justify-between mx-6 relative" data-astro-cid-dmqpwcec> <button class="menu-toggle w-8 h-8 -ml-1 flex items-center justify-center relative z-30 md:hidden" aria-label="Open Menu" aria-expanded="false" aria-controls="menu-items" data-astro-cid-dmqpwcec> <span class="menu-toggle-icon w-6 h-px relative bg-current" data-astro-cid-dmqpwcec></span> </button> <div class="flex gap-2" data-astro-cid-dmqpwcec> <a rel="noreferrer" href="https://www.linkedin.com/in/caleb-diehl-a93a6984" target="_blank" class="transition-transform hover:scale-110" data-astro-cid-dmqpwcec> <svg fill="#fff" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32" data-astro-cid-dmqpwcec><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z" data-astro-cid-dmqpwcec></path></svg> </a> <a rel="noreferrer" href="https://github.com/csdiehl16" target="_blank" class="transition-transform hover:scale-110" data-astro-cid-dmqpwcec> <svg viewBox="0 0 98 96" width="24" height="24" xmlns="http://www.w3.org/2000/svg" data-astro-cid-dmqpwcec><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z" fill="#fff" data-astro-cid-dmqpwcec></path></svg> </a> </div> <div class="glass-cyan" data-astro-cid-dmqpwcec> <ul id="menu-items" class="menu flex gap-6 md:flex-row md:visible md:opacity-100 md:static md:max-w-none md:p-0 md:border-0" data-astro-cid-dmqpwcec> <li class="py-1" data-astro-cid-dmqpwcec> <a class="flex items-center gap-2 text-sm text-gray-400 hover:text-main md:text-sm md:font-semibold" href="/" data-astro-cid-dmqpwcec> <svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" data-astro-cid-dmqpwcec><path d="M5 1C5 0.447715 5.44772 0 6 0H9C9.55228 0 10 0.447715 10 1V2H14C14.5523 2 15 2.44772 15 3V6C15 6.8888 14.6131 7.68734 14 8.23608V11.5C14 12.3284 13.3284 13 12.5 13H2.5C1.67157 13 1 12.3284 1 11.5V8.2359C0.38697 7.68721 0 6.88883 0 6V3C0 2.44772 0.447716 2 1 2H5V1ZM9 1V2H6V1H9ZM1 3H5H5.5H9.5H10H14V6C14 6.654 13.6866 7.23467 13.1997 7.6004C12.8655 7.85144 12.4508 8 12 8H8V7.5C8 7.22386 7.77614 7 7.5 7C7.22386 7 7 7.22386 7 7.5V8H3C2.5493 8 2.1346 7.85133 1.80029 7.60022C1.31335 7.23446 1 6.65396 1 6V3ZM7 9H3C2.64961 9 2.31292 8.93972 2 8.82905V11.5C2 11.7761 2.22386 12 2.5 12H12.5C12.7761 12 13 11.7761 13 11.5V8.82915C12.6871 8.93978 12.3504 9 12 9H8V9.5C8 9.77614 7.77614 10 7.5 10C7.22386 10 7 9.77614 7 9.5V9Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd" data-astro-cid-dmqpwcec></path></svg>Projects </a> </li><li class="py-1" data-astro-cid-dmqpwcec> <a class="flex items-center gap-2 text-sm text-gray-400 hover:text-main md:text-sm md:font-semibold" href="/about" data-astro-cid-dmqpwcec> <svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" data-astro-cid-dmqpwcec><path d="M7.5 0.875C5.49797 0.875 3.875 2.49797 3.875 4.5C3.875 6.15288 4.98124 7.54738 6.49373 7.98351C5.2997 8.12901 4.27557 8.55134 3.50407 9.31167C2.52216 10.2794 2.02502 11.72 2.02502 13.5999C2.02502 13.8623 2.23769 14.0749 2.50002 14.0749C2.76236 14.0749 2.97502 13.8623 2.97502 13.5999C2.97502 11.8799 3.42786 10.7206 4.17091 9.9883C4.91536 9.25463 6.02674 8.87499 7.49995 8.87499C8.97317 8.87499 10.0846 9.25463 10.8291 9.98831C11.5721 10.7206 12.025 11.8799 12.025 13.5999C12.025 13.8623 12.2376 14.0749 12.5 14.0749C12.7623 14.075 12.975 13.8623 12.975 13.6C12.975 11.72 12.4778 10.2794 11.4959 9.31166C10.7244 8.55135 9.70025 8.12903 8.50625 7.98352C10.0187 7.5474 11.125 6.15289 11.125 4.5C11.125 2.49797 9.50203 0.875 7.5 0.875ZM4.825 4.5C4.825 3.02264 6.02264 1.825 7.5 1.825C8.97736 1.825 10.175 3.02264 10.175 4.5C10.175 5.97736 8.97736 7.175 7.5 7.175C6.02264 7.175 4.825 5.97736 4.825 4.5Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd" data-astro-cid-dmqpwcec></path></svg>About </a> </li><li class="py-1" data-astro-cid-dmqpwcec> <a class="flex items-center gap-2 text-sm text-gray-400 hover:text-main md:text-sm md:font-semibold" href="/blog" data-astro-cid-dmqpwcec> <svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" data-astro-cid-dmqpwcec><path d="M4.2 1H4.17741H4.1774C3.86936 0.999988 3.60368 0.999978 3.38609 1.02067C3.15576 1.04257 2.92825 1.09113 2.71625 1.22104C2.51442 1.34472 2.34473 1.51442 2.22104 1.71625C2.09113 1.92825 2.04257 2.15576 2.02067 2.38609C1.99998 2.60367 1.99999 2.86935 2 3.17738V3.1774V3.2V11.8V11.8226V11.8226C1.99999 12.1307 1.99998 12.3963 2.02067 12.6139C2.04257 12.8442 2.09113 13.0717 2.22104 13.2837C2.34473 13.4856 2.51442 13.6553 2.71625 13.779C2.92825 13.9089 3.15576 13.9574 3.38609 13.9793C3.60368 14 3.86937 14 4.17741 14H4.2H10.8H10.8226C11.1306 14 11.3963 14 11.6139 13.9793C11.8442 13.9574 12.0717 13.9089 12.2837 13.779C12.4856 13.6553 12.6553 13.4856 12.779 13.2837C12.9089 13.0717 12.9574 12.8442 12.9793 12.6139C13 12.3963 13 12.1306 13 11.8226V11.8V3.2V3.17741C13 2.86936 13 2.60368 12.9793 2.38609C12.9574 2.15576 12.9089 1.92825 12.779 1.71625C12.6553 1.51442 12.4856 1.34472 12.2837 1.22104C12.0717 1.09113 11.8442 1.04257 11.6139 1.02067C11.3963 0.999978 11.1306 0.999988 10.8226 1H10.8H4.2ZM3.23875 2.07368C3.26722 2.05623 3.32362 2.03112 3.48075 2.01618C3.64532 2.00053 3.86298 2 4.2 2H10.8C11.137 2 11.3547 2.00053 11.5193 2.01618C11.6764 2.03112 11.7328 2.05623 11.7613 2.07368C11.8285 2.11491 11.8851 2.17147 11.9263 2.23875C11.9438 2.26722 11.9689 2.32362 11.9838 2.48075C11.9995 2.64532 12 2.86298 12 3.2V11.8C12 12.137 11.9995 12.3547 11.9838 12.5193C11.9689 12.6764 11.9438 12.7328 11.9263 12.7613C11.8851 12.8285 11.8285 12.8851 11.7613 12.9263C11.7328 12.9438 11.6764 12.9689 11.5193 12.9838C11.3547 12.9995 11.137 13 10.8 13H4.2C3.86298 13 3.64532 12.9995 3.48075 12.9838C3.32362 12.9689 3.26722 12.9438 3.23875 12.9263C3.17147 12.8851 3.11491 12.8285 3.07368 12.7613C3.05624 12.7328 3.03112 12.6764 3.01618 12.5193C3.00053 12.3547 3 12.137 3 11.8V3.2C3 2.86298 3.00053 2.64532 3.01618 2.48075C3.03112 2.32362 3.05624 2.26722 3.07368 2.23875C3.11491 2.17147 3.17147 2.11491 3.23875 2.07368ZM5 10C4.72386 10 4.5 10.2239 4.5 10.5C4.5 10.7761 4.72386 11 5 11H8C8.27614 11 8.5 10.7761 8.5 10.5C8.5 10.2239 8.27614 10 8 10H5ZM4.5 7.5C4.5 7.22386 4.72386 7 5 7H10C10.2761 7 10.5 7.22386 10.5 7.5C10.5 7.77614 10.2761 8 10 8H5C4.72386 8 4.5 7.77614 4.5 7.5ZM5 4C4.72386 4 4.5 4.22386 4.5 4.5C4.5 4.77614 4.72386 5 5 5H10C10.2761 5 10.5 4.77614 10.5 4.5C10.5 4.22386 10.2761 4 10 4H5Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd" data-astro-cid-dmqpwcec></path></svg>Blog </a> </li> </ul> </div> </div> </nav>   <main class="grow w-full mx-auto max-w-5xl">  <article class="relative z-0 flex flex-1 flex-col"> <div class="mx-auto w-full max-w-screen-lg md:-mb-10 lg:-mb-12 xl:-mb-16"> <img class="object-cover w-full min-h-[240px]" src="/ai_images/ai_scatter_example.png"> </div> <header class="p-8 bg-main max-w-screen-md mx-auto mb-8"> <h1 class="text-3xl leading-tight font-medium sm:text-5xl sm:leading-tight">Building an AI-powered data explorer</h1> <div class="mt-4 text-sm"> <time datetime="2024-03-29T07:00:00.000Z"> March 29, 2024 </time>  </div> </header> <div class="max-w-full md:max-w-screen-md text-md mx-auto"> <p>Exploring data should feel natural, like conducting an interview with an expert. However, analysts write their queries in code. It’s easy to get bogged down in syntax errors, forgetting parentheses, typing in complex chart specifications, or messing up variable names.</p>
<p>To reach that natural process of inquiry, I created an AI assistant for exploratory data analysis and prototyping visualizations. Here were my requirements:</p>
<ul>
<li>Ask natural language questions and get answers from a dataset.</li>
<li>Return simple visualizations and summary tables based on the questions, without me having to choose the visualizations or code them myself.</li>
</ul>
<p>I took advantage of <a href="https://sdk.vercel.ai/docs">Vercel’s AI SDK 3.0</a>, which uses <a href="https://nextjs.org/docs/app/building-your-application/rendering/server-components">React Server Components</a> to return streamable bits of UI from the AI back to the client. I combined this with <a href="https://observablehq.com/plot/">Observable Plot,</a> a high-level and flexible chart prototyping library to ask questions and get back charts.</p>
<div style="border:1px solid lightgrey;border-radius: 8px;padding:16px;">
Try out the deployed project <a style="font-weight:bold;" rel="noreferrer" target="_blank" href="https://ai-data-assistant.vercel.app/login">here! </a><br>
<a style="font-weight:bold;" rel="noreferrer" target="_blank" href="https://github.com/csdiehl/ai-data-assistant">Here's the repo</a> if you want to check out the code, run it locally, or contribute to the project!
</div>
<p><strong>In this post, I’ll walk through how I applied a few key AI concepts. Look out for these terms:</strong></p>
<ul>
<li>Function calling</li>
<li>Text-to-sql</li>
<li>Generative UI</li>
<li>Structured Output</li>
<li>Few-shot prompting</li>
</ul>
<p><img src="/ai_images/bitcoin_line.png" alt="An interactive notebook for visualizing data using AI"></p>
<h2 id="retrieving-data-from-natural-language-prompts">Retrieving data from natural language prompts</h2>
<p><strong>Essentially there are three steps in what I needed to do:</strong></p>
<ul>
<li>Turn a natural language query into a SQL, Javascript or Python expression</li>
<li>Run it and get back a Javascript array of objects</li>
<li>Plug that data into the ideal visualization, chosen through a combination of the LLM and hard-coded logical statements</li>
</ul>
<p>The first step was getting from a regular English question to a code snippet that can return data. Certain LLMs, including recent OpenAI models, can <strong>call functions.</strong> In the system prompt, you can reference functions that the LLM can use to augment its capabilities.</p>
<p>For example, LLMs are good at text, but bad at math. They only predict the next words in a sequence. So you could give it a “calculator” tool, and tell it to use that every time you need to add.</p>
<p>In my first crude version, I created different functions for different operations on the data. I uploaded JSON files and stored them in memory as Javascript arrays. I used methods from the <a href="https://d3js.org/">D3.js library</a> to sort, summarize and filter. I used <strong>few-shot prompting</strong> to hint at which tool to use, and what parameters to include.</p>
<p>This proved extremely tedious, because I had to write new functions for even simple operations, using Javascript, which is a terrible data analysis language. I needed to make queries specific to clue in the LLM to the right tool for the job.</p>
<p>I figured a much more flexible tool would be <strong><a href="https://python.langchain.com/docs/integrations/toolkits/sql_database">text-to-sql.</a></strong> This is an active research area in getting LLMs to take a natural language question and translate it into a syntactically correct SQL query.</p>
<p>Here’s what my data retrieval tool ended up looking like. The name and description fields help the LLM decided when it use the tool. The parameters, which I’ll detail later on, are arguments that the LLM will fill in and pass to a function to execute.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>  {</span></span>
<span class="line"><span>        name: "summarize_data",</span></span>
<span class="line"><span>        description:</span></span>
<span class="line"><span>          "Create a summary of the data, grouping one variable by another.",</span></span>
<span class="line"><span>        parameters:</span></span>
<span class="line"><span>        ...</span></span>
<span class="line"><span>  }</span></span>
<span class="line"><span></span></span></code></pre>
<p>In the system prompt, you can instruct the LLM to use it like this:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>To use your query to interact with the database, call \`summarize_data\`.</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span></code></pre>
<p>Taking this route meant that I needed a database.</p>
<h2 id="where-to-store-the-data">Where to store the data</h2>
<p>For this task, I didn’t need to persist the data beyond a single user session. I also just wanted to look at one dataset, or table, at a time. I wanted to stay focused on refining the LLM’s response to prompts and building a seamless <strong>generative UI.</strong></p>
<p>So in today’s ecosystem I had a lot of choices.</p>
<p><strong>I tried all of these things</strong></p>
<ul>
<li>Just store the data in React state, and use a library like <a href="https://github.com/AlaSQL/alasql">alasql</a> to make SQL-like queries to Javascript arrays</li>
<li>Store the data on the client using <a href="https://duckdb.org/docs/api/wasm/overview.html">DuckDB-WASM</a></li>
<li>Store the data on server in a persistent sqlite3 database file</li>
<li>Store the data in-memory on the server, using sqlite.</li>
</ul>
<p>I ended up going with option 4, with the intention of eventually shifting to option 3 so I can save a list of datasets I’m working on. Option 1 provided no opportunity to shift to more persistent storage later.</p>
<p>Option 2 was promising. DuckDB is a newer embedded database that’s supposed to be optimized for data analytics, compared to sqlite. DuckDB-WASM runs in the browser using web assembly. That means you can store all your data client-side and make SQL queries to it.</p>
<p>In fact, another (nice-looking and faster) version of what I did goes this route. You should <a href="https://www.duckbook.ai/">check this out</a> as well! I used that developer’s <a href="https://github.com/holdenmatt/duckdb-wasm-kit">open-source React bindings</a> for DuckDB-WASM to load a database in the browser.</p>
<p>But the catch was that I couldn’t access the client-side DB from the server, where all the AI action was happening. Although the chart component renders on the client side, the logic for rendering lives in the server component.</p>
<p>The closest solution I could think of was using <a href="https://legacy.reactjs.org/docs/context.html">React Context</a> to wrap the messages in a provider with the database, and access those from the Chart component. But this would make it difficult to eventually chain queries together - for example to get SQL, then turn that into natural language.</p>
<p>I ended up going with the in-memory <a href="https://www.npmjs.com/package/sqlite3">sqlite3</a> database set up on the server using Node sqlite. I used <a href="https://www.papaparse.com/">Papaparse</a> to parse CSVs, then some server-side code to extract the schema and other metadata and insert the rows into the db.</p>
<p><img src="/ai_images/ai_file_upload.png" alt="Uploading files to the AI data explorer"></p>
<p>The text-to-SQL pipeline greatly reduced the lines of code I needed. I only needed one flexible tool to provide to the LLM.</p>
<p>To ensure success, I included some critical guidance in the system prompt. The LLM is helpless without the database schema. It also helps to include a few sample rows. Think of what a human data analyst does - the first instinct is to check data types and column names, and peek at a few rows.</p>
<p>Vercel AI SDK allows you to track shared variables that are needed on both the client and server in something called the AI state. Normally, this is just an array of messages, but it can be any Javascript object. I modified it to include both a message array and certain metadata, like column names, about the file the user uploaded. The shared state looks like this:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span></span></span>
<span class="line"><span>// Define the initial state of the AI. It can be any JSON object.</span></span>
<span class="line"><span>const initialAIState: {</span></span>
<span class="line"><span>  sampleData: any[]</span></span>
<span class="line"><span>  dataKey: string</span></span>
<span class="line"><span>  columns: string[]</span></span>
<span class="line"><span>  tableName: string</span></span>
<span class="line"><span>  schema: string</span></span>
<span class="line"><span>  topK: number</span></span>
<span class="line"><span>  dataSummary: any[]</span></span>
<span class="line"><span>  messages: {</span></span>
<span class="line"><span>    role: "user" | "assistant" | "system" | "function"</span></span>
<span class="line"><span>    content: string</span></span>
<span class="line"><span>    id?: string</span></span>
<span class="line"><span>    name?: string</span></span>
<span class="line"><span>  }[]</span></span>
<span class="line"><span>} = {</span></span>
<span class="line"><span>  sampleData: [],</span></span>
<span class="line"><span>  dataKey: "",</span></span>
<span class="line"><span>  messages: [],</span></span>
<span class="line"><span>  columns: [],</span></span>
<span class="line"><span>  tableName: "",</span></span>
<span class="line"><span>  schema: "",</span></span>
<span class="line"><span>  topK: 5000,</span></span>
<span class="line"><span>  dataSummary: [], // this will hold all the data for a short time, then summaries</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span></code></pre>
<p>In my database setup function, I store the sample and schema in the shared UI and AI state, and inject these strings into the prompt.</p>
<h2 id="building-a-chart-from-a-data-summary">Building a chart from a data summary</h2>
<p>After asking a question, getting back SQL from the LLM and running this to retrieve data, I needed to visualize it.</p>
<p>I asked the LLM to generate some encodings (mappings of data to visual variables like color and size) at the same time it created the query. I used the <a href="https://zod.dev/">Zod</a> schema-mapping library to coerce its responses into a <strong>structured output.</strong></p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span></span></span>
<span class="line"><span>   x: z.string().describe("The x-axis variable."),</span></span>
<span class="line"><span>              y: z.string().optional().describe("The y-axis variable."),</span></span>
<span class="line"><span>              size: z</span></span>
<span class="line"><span>                .string()</span></span>
<span class="line"><span>                .optional()</span></span>
<span class="line"><span>                .describe("The variable to be represented by size."),</span></span>
<span class="line"><span>              color: z.optional(</span></span>
<span class="line"><span>                z.string().describe("The variable to be represented by color.")</span></span>
<span class="line"><span>              ),</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span></code></pre>
<p>This way, I could be sure I was getting all the required variables for the chart, in the right format, from the LLM’s choices. These included x, y, color, and size encoding, and a chart title. Similar to a <strong>few-shot prompting</strong> approach, I included guidance in the system prompt on when you might use certain chart types and encodings.</p>
<p>At first, I exerted more control - using Zod to force the encodings to actual variable names. This turned out to not be necessary. The LLM is great at taking messy input and figuring out which variable you’re talking about. You can ask about cars in the United States, and it will figure out you want to filter the Origin variable to USA. Often, the LLM makes up its own names as aliases in the SQL and uses those.</p>
<p>In a client-side component, I have some logic to take the LLM’s chart specification and render it using Observable Plot. The LLM still has trouble deciding on different charts, but generally does a good job, especially with additional prompting.</p>
<p>Of course, this structured approach limits the LLM’s creativity. Ideally, I wanted to let it generate its own chart code from scratch.</p>
<p>It did a great job generating code, but I as of right now, haven’t found a great way to convert the string that it returns into executable code. I tried using <a href="https://www.w3schools.com/jsref/jsref_eval.asp">Javascript’s eval()</a> and function constructor, which takes a string argument. However this is a dangerous, some say “evil” function, that can easily crash the application or create a security vulnerability.</p>
<h2 id="finishing-touches-with-streaming-ui">Finishing touches with streaming UI</h2>
<p>In many ways, it would have been easier to build this app using traditional client-server communication through REST APIs. I could have used <a href="https://js.langchain.com/docs/get_started/introduction">Langchain</a>, which is not as easy to integrate into Vercel’s Server Components setup as they make it sound. But I stuck with the server components mainly to test out a key new feature.</p>
<p>It’s called <a href="https://vercel.com/blog/how-streaming-helps-build-faster-web-applications">getStreamableUI,</a> and it’s awesome. Instead of streaming just chunks of text, you can stream entire React components. This allows you to build up complex UIs piece by piece, as the LLM returns information.</p>
<p>Here’s what it looks like. As soon as I receive the user message on the server, I immediately render a placeholder card to give instant feedback.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>  const reply = createStreamableUI(</span></span>
<span class="line"><span>    &#x3C;ResponseCard title={"thinking..."} caption={""}></span></span>
<span class="line"><span>      &#x3C;SkeletonChart /></span></span>
<span class="line"><span>    &#x3C;/ResponseCard></span></span>
<span class="line"><span>  )</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span></code></pre>
<p>Then I run the AI completion. As soon as the LLM comes back with a SQL query, we can update the UI with the query it’s running and the type of chart it plans to make.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span></span></span>
<span class="line"><span> completion.onFunctionCall("summarize_data", async ({ query, chartSpec }) => {</span></span>
<span class="line"><span>    const { x, y, title, type, color, size } = chartSpec</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    reply.update(</span></span>
<span class="line"><span>      &#x3C;ResponseCard title={title} caption={query}></span></span>
<span class="line"><span>        &#x3C;SkeletonChart></span></span>
<span class="line"><span>          Building {type} chart of {x}, {y}, {color}</span></span>
<span class="line"><span>        &#x3C;/SkeletonChart></span></span>
<span class="line"><span>      &#x3C;/ResponseCard></span></span>
<span class="line"><span>    )</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    // then start generating the chart</span></span>
<span class="line"><span></span></span>
<span class="line"><span> })</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span></code></pre>
<p>Finally, I actually run the query on the database and render the chart. When the UI is complete, we mark it as done.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span></span></span>
<span class="line"><span> const component =</span></span>
<span class="line"><span>      type === "table" ? (</span></span>
<span class="line"><span>        &#x3C;ResponseCard title={title} caption={query}></span></span>
<span class="line"><span>          &#x3C;Table data={response} xVar={x} /></span></span>
<span class="line"><span>        &#x3C;/ResponseCard></span></span>
<span class="line"><span>      ) : (</span></span>
<span class="line"><span>        &#x3C;ResponseCard title={title} caption={query}></span></span>
<span class="line"><span>          &#x3C;Chart</span></span>
<span class="line"><span>            type={type}</span></span>
<span class="line"><span>            data={response}</span></span>
<span class="line"><span>            dataKey={dataKey}</span></span>
<span class="line"><span>            x={x}</span></span>
<span class="line"><span>            y={y}</span></span>
<span class="line"><span>            size={size}</span></span>
<span class="line"><span>            color={color}</span></span>
<span class="line"><span>          /></span></span>
<span class="line"><span>        &#x3C;/ResponseCard></span></span>
<span class="line"><span>      )</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    reply.done(component)</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span></code></pre>
<p>Finally, I added controls to make corrections when LLM goes wrong, such as flipping the chart, and showing the query. I aim to make data exporting and importing as seamless as possible. You can bring data from a csv or JSON at a URL, or on your computer, and export the LLM’s summaries as csv.</p>
<p>Here’s my attempt to make it produce the famous gapminder chart by Hans Rosling.</p>
<p><img src="/ai_images/ai_gapminder.png" alt="Gapminder chart generated by AI"></p>
<p>…Not quite…but we’re getting there.</p>
<h2 id="future-goals">Future goals</h2>
<p>This is just the beginning. One important feature I hope to implement next is follow-up questions. In the Vercel AI SDK you can keep track of message history in a shared state between AI and the client side, and feed this back into the model prompt on every call.</p>
<p>With the data analysis it’s a bit more complex because I need to direct the LLM to find and use the correct summarized dataset from the last relevant prompt.</p>
<p>In the future, it would be great to allow users to create accounts, save their analyses, and meter their usage of the OpenAI API. Until I implement these features, you can clone the project locally, swap in your own API key, and be up and running.</p>
<p>I’d love to collaborate with others on this. If you’d like to <a href="https://github.com/csdiehl/ai-data-assistant/issues">contribute to this project,</a> feel free to tackle an issue in the repo or open a PR for a new feature!</p> </div> <div class="mt-8 flex flex-wrap items-center gap-6 text-sm justify-between sm:mt-12 sm:text-base"> <div class="flex flex-wrap gap-x-5 gap-y-1 text-sm"> <a class="text-main hover:underline" href="/tags/javascript">
#Javascript </a><a class="text-main hover:underline" href="/tags/data-visualization">
#Data Visualization </a><a class="text-main hover:underline" href="/tags/ai">
#AI </a><a class="text-main hover:underline" href="/tags/llm">
#LLM </a><a class="text-main hover:underline" href="/tags/vercel-ai-sdk">
#Vercel AI SDK </a><a class="text-main hover:underline" href="/tags/open-ai">
#Open AI </a><a class="text-main hover:underline" href="/tags/observable">
#Observable </a> </div> <button class="inline-flex items-center justify-center px-6 py-2 text-sm leading-tight italic  text-main bg-main border border-main rounded-full transition hover:bg-muted copy-url-button" aria-label="Copy link" data-url="https://csdiehl16.github.io/blog/post-3/" data-tooltip-default="Copy link" data-tooltip-success="Copied">Share</button> </div> </article> <div class="my-16 sm:my-24"> <h2 class="mb-12 text-xl italic sm:mb-16 sm:text-2xl">Read Next</h2>  <a class="flex justify-between items-start gap-8 group mb-10 sm:mb-12" href="/blog/post-2/"> <div class="glass-cyan-muted p-0 shrink-0"> <img src="/observable_images/globe.png" alt="Description of the image" class="grayscale w-48 h-48 object-cover rounded-lg"> </div> <div class="grow"> <h3 class="text-xl leading-tight font-medium group-hover:underline group-hover:decoration-dashed group-hover:underline-offset-4 group-hover:decoration-1 sm:text-2xl">Observations on the new Observable 2.0 Framework</h3> <div class="mt-1 text-sm leading-normal"> <time datetime="2024-03-13T07:00:00.000Z"> March 13, 2024 </time>  </div> <div class="mt-3 text-sm leading-normal">My thoughts on Observable&#39;s latest creation.</div> </div> <div class="hidden italic opacity-0 transition group-hover:opacity-100 sm:inline-flex sm:gap-1 sm:items-center sm:shrink-0">
Read Post <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current w-4 h-4"> <path d="M4.286 12c0-0.533 0.432-0.964 0.964-0.964v0h11.172l-4.14-4.138c-0.175-0.175-0.283-0.416-0.283-0.683 0-0.533 0.432-0.965 0.965-0.965 0.267 0 0.508 0.108 0.683 0.283v0l5.785 5.785c0.175 0.175 0.283 0.416 0.283 0.683s-0.108 0.508-0.283 0.683l-5.785 5.785c-0.175 0.175-0.416 0.283-0.683 0.283-0.533 0-0.965-0.432-0.965-0.965 0-0.267 0.108-0.508 0.283-0.683v0l4.14-4.138h-11.172c-0.533 0-0.964-0.432-0.964-0.964v0z"></path> </svg> </div> </a> </div> </main> <footer class="w-full max-w-3xl mx-auto pt-12 pb-10 sm:pt-24 sm:pb-14"> <div class="glass-cyan pt-6 flex flex-col gap-4 sm:flex-row-reverse sm:justify-between sm:items-center"> <div class="flex flex-wrap gap-x-4 gap-y-1"> <a class="inline-flex items-center justify-center text-sm hover:underline hover:underline-offset-2" href="https://www.linkedin.com/in/caleb-diehl-a93a6984" target="_blank" rel="noopener noreferer"> Linkedin </a><a class="inline-flex items-center justify-center text-sm hover:underline hover:underline-offset-2" href="https://github.com/csdiehl16" target="_blank" rel="noopener noreferer"> Github </a> </div> <p class="text-sm">
&copy; 2025&nbsp;<a class="hover:underline hover:underline-offset-2" href="/">Caleb Diehl</a>. All rights reserved.
</p> </div> </footer> </div> </body></html> 